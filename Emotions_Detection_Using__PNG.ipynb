{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Emotions_Detection_Using_.PNG.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paramjeetsharma/Machine_Learning/blob/master/Emotions_Detection_Using__PNG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHw5nw-lGoSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b318f830-23d3-45d6-9abd-b7c9b4bb4b54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSXvdVTcDbn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6ef054b8-c9ea-4960-9d3a-302bd270c5bc"
      },
      "source": [
        "train = []\n",
        "test = []\n",
        "\n",
        "import os\n",
        "\n",
        "list = os.listdir('/gdrive/My Drive/Emotions') # dir is your directory path\n",
        "number_files = len(list)\n",
        "train.append(number_files)\n",
        "print (number_files)\n",
        "print(train)\n",
        "\n",
        "import os\n",
        "list = os.listdir('/gdrive/My Drive/Emotions') # dir is your directory path\n",
        "number_files = len(list)\n",
        "test.append(number_files)\n",
        "print (number_files)\n",
        "print(test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[5]\n",
            "5\n",
            "[5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bucIP-WPDbn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVU3Wf_WLsa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D\n",
        "from tensorflow.python.keras.layers import MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Flatten\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzcJtKmlDbn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (48,48,3), activation = 'relu'))\n",
        "\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSweEIdDboA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 7, activation = 'softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmAK_jB9DboD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S2jfjjVDboF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yx6NSwkDboI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c8466804-2039-497e-f5d3-6b6d8046cd93"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/gdrive/My Drive/Emotions/train',\n",
        "                                                 target_size = (48,48),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/gdrive/My Drive/Emotions/test',\n",
        "                                            target_size = (48,48),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4578 images belonging to 7 classes.\n",
            "Found 0 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BnHI4GDboP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d54e9983-756f-45d6-cf4f-d1193c70ad27"
      },
      "source": [
        "training_set.class_indices"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 0,\n",
              " 'disgusted': 1,\n",
              " 'fearful': 2,\n",
              " 'happy': 3,\n",
              " 'neutral': 4,\n",
              " 'sad': 5,\n",
              " 'surprised': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZB6vpHDboU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dcef938b-f000-4500-8f7e-cfa07e4671cd"
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = 12442,\n",
        "                         epochs = 25,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 3117)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "    2/12442 [..............................] - ETA: 31:20:32 - loss: 1.3524 - accuracy: 0.3438"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89cfEqjuDboY",
        "colab_type": "code",
        "colab": {},
        "outputId": "49a33a3e-b58b-4394-9ef9-64ef9aeb8d3d"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "#saving the  model to be used later\n",
        "fer_json = classifier.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "classifier.save_weights(\"emotion_detection_fer.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os6N3oWCDbod",
        "colab_type": "code",
        "colab": {},
        "outputId": "f963e2b2-8710-48d8-b0e2-5ae6b70e3e4e"
      },
      "source": [
        "#loading the model\n",
        "json_file = open('fer.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"emotion_detection_fer.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQtbA6rDboi",
        "colab_type": "code",
        "colab": {},
        "outputId": "2519c1bd-72fe-43cb-c770-830450943219"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('prediction/Happy1.png', target_size = (48,48))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "result = result.astype(int).flatten()\n",
        "\n",
        "if result[0] == 1:\n",
        "    prediction = 'angry'\n",
        "elif result[1] == 1:\n",
        "    prediction = 'disgusted'\n",
        "elif result[2] == 1:\n",
        "    prediction = 'fearful'\n",
        "elif result[3] == 1:\n",
        "    prediction = 'happy'\n",
        "elif result[4] == 1:\n",
        "    prediction = 'neutral'\n",
        "elif result[5] == 1:\n",
        "    prediction = 'sad'\n",
        "else:\n",
        "    prediction = 'surprised'\n",
        "    \n",
        "\n",
        "print(f'The Image you have feed to me is image of a {prediction} person')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Image you have feed to me is image of a happy person\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8N7t1ILDbop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}